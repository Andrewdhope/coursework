- Week 1
	+ The ultimate standard for strengthening scientific evidence is replication of findings
	+ Can't usually replicate the whole experiment, but you can reproduce the computation with the original data
	+ High throughput data generation, every field has a computational version of it (e.g. computational biology)
	+ Required elements
		- Analytic data (not necessarily raw data)
		- Analytic code
		- Documentation of code and data
		- Standard means of transportation
	+ Literate (Statistical) Programming
		- Analysis described in a series of text and code chunks
			+ Sweave -- LaTeX plus R
			+ knitr -- modern alternative for sweave
				- R plus Markdown, HTML, LaTeX
		- Script everything. No user input required. 
	+ knitr
		- 
		
	+ Steps in Data Analysis
		- Define the question
			+ The most powerful dimension reduction techinque
		- Define the ideal data set
		- Determine what data you can access
		- Obtain the data
			+ Try to obtain the raw data
			+ Always reference the source
				- If using an internet source, include the url and the time accessed
		- Clean the data
		- Exploratory data analysis
		- Statistical prediction/modeling
		- Interpret results
		- Challenge results
		- Synthesize/write up results
			+ Lead with the question
			+ Explain and order the analysis in the context of a story
		- Create reproducible code
			+ knitr to preserve code and documentation in a single document
	+ Organizing data analysis
		- Raw data transformed to (tidy) processed data. Transformation should be documented in a readme.
- Week 2
	+ Coding standards in R
		- Always use files / text editor
		- Indent your code (4 spaces)
		- Limit line length (80 characters)
		- Split up your functions
	+ Markdown
		- write/read in an easy format that automatically converts to XHTML
		- # headings
		- * italics, ** bold
		- - unordered list
		- (1, 2, 3) ordered list
		- [links](http://url)
		- newlines created with a double space at the end of the line
		- can insert standalone html elements
	+ R Markdown (.rmd)
		- lets you embed R code within a markdown file
		- R markdown can be converted to regular markdown with knitr
		- Markdown is converted to HTML with the markdown package
		- to write r code: ```{r nameoptional, echo = TRUE, results = "hide"}, close it with ```
		- .rmd >> .md >> .html
		- Inline text computations
			+ The current time is `r time`. 
			+ variables come from an earlier code chunk
		- HTML embeds the full image using base64 code, resulting in a true stand-along html document
		- xtable package can generate HTML tables for you
		- Set global options by changing opts_chunk$set
		- Useful options:
			+ results: "asis", "hide"
			+ echo: TRUE, FALSE
			+ fig.height, fig.width
		- Caching computations
			+ cache=TRUE option will save the results to disk, and will load from cache until the data or code changes
			+ dependencies aren't automatically checked
		
	+ knitr
		- built into R Studio
		- can export to PDF or HTML
		- good for medium-length, more formatted documents
			+ Manuals, tutorials, reports
		- not good for very large documents, complex formatting, or documents with heavy computations

- Week 3
	+ Communicating Results
		- Research paper format -- title, abstract, body/analysis/results, supplementary details, code/data
		- Write concise emails
	+ RPubs
		- R-studio site to publish knitr and such
		- Just puts your markdown on the web for you
	+ Reproducible research checklist
		- Start with Good Science -- coherent, focused question
		- Script everything. Don't do anything manually. Don't point and click. -- editing spreadsheets, downloading datasets
		- Teach a computer to do it. This guarantees reproducibility.
		- Use some version control -- slow things down, add in small chunks with comments
		- Keep track of your software environment -- CPU (intel, ARM, AMD), OS, 'software toolchain', libraries, packages, other dependencies
			+ sessionInfo() gives you much of this
		- Don't save output until the very end
		- Set your seed when using random number generators
		- Ensure quality throughout the entire pipeline
	+ Evidence-based data analysis
		- Reproducibility does not guarantee validity of the original analysis
		- Mistakes upstream will be sent down, and may or may not be caught when reproduced
		- Suggestion of a "Deterministic Statistical Machine" to prescribe a data analysis pipeline with minimal input
			+ Libraries tailored to scientific areas and questions being asked
			+ If standards are followed, you can quickly agree that analysis is likely valid	
			+ Assigned to fix? Futured?

- Week 4
	+ Caching Computations
		- Raw data > processing code > tidy data > analytic code > computed conclusions > presentation code > output
		- Store your computational results in an available database	
		- cacher package
			+ puts code and data in a bundle to distribute
			+ parses source file
			+ creates directories and subdirectories
			+ cycle through expression and evaluate it and store objects and metadata
			+ creates a SHA-1 hash that others can read and clone with cacher
				- data not loaded by default
			+ funtions	
				+ runcode
				+ checkcode
				+ checkobject
				+ loadcache